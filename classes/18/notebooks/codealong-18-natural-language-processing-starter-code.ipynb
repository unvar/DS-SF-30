{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS-SF-30 | Codealong 18: Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >>> One-time setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import nltk\n",
    "nltk.download()\n",
    "'''\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <<< One-time setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vdodla/anaconda/envs/ga-course/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "\n",
    "import string\n",
    "import re\n",
    "import unicodedata\n",
    "from nltk import tokenize, corpus, stem\n",
    "\n",
    "from sklearn import feature_extraction, linear_model, ensemble, cross_validation, metrics, decomposition\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_text(document):\n",
    "    document = document.encode('utf-8')\n",
    "\n",
    "    # Convert text to lowercase\n",
    "    document = document.lower()\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = tokenize.word_tokenize(document)\n",
    "\n",
    "    # Remove punctuation in tokens and then remove empty tokens\n",
    "    tokens = [re.sub('java:\\d+', '', token) for token in tokens]\n",
    "    tokens = [token.translate(None, string.punctuation) for token in tokens]\n",
    "    tokens = [token for token in tokens if token]\n",
    "\n",
    "    # Remove stop words\n",
    "    tokens = [token for token in tokens if not token in corpus.stopwords.words('english')]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentence', 'wait', 'another', 'third']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenize_text(\"This is a sentence...  Wait, here's another.  And a third!\")\n",
    "# x = '''\n",
    "# Exception in thread \"main\" java.lang.NullPointerException\n",
    "#         at com.example.myproject.Book.getTitle(Book.java:16)\n",
    "#         at com.example.myproject.Author.getBookTitles(Author.java:25)\n",
    "#         at com.example.myproject.Bootstrap.main(Bootstrap.java:14)\n",
    "# '''\n",
    "# tokens = tokenize_text(x)\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Stemmer:\n",
    "    stemmer = stem.porter.PorterStemmer()\n",
    "\n",
    "    @staticmethod\n",
    "    def stem_tokens(tokens):\n",
    "        return [Stemmer.stemmer.stem(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'sentenc', 'wait', u'anoth', 'third']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = Stemmer.stem_tokens(tokens)\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will be analyzing a partial list of the reviews for J.K. Rowling's The Casual Vacancy.  (https://www.amazon.com/dp/0316228532)\n",
    "\n",
    "Our dataset is a subset of http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Books_5.json.gz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('..', 'datasets', 'dataset-18-reviews.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-11</td>\n",
       "      <td>R3SH1N77GNTD9K</td>\n",
       "      <td>Stefi</td>\n",
       "      <td>Great read</td>\n",
       "      <td>Very moving story. Great effortless writing wh...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-11</td>\n",
       "      <td>RVOEQK3JK4LY2</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>Great book! Does not disappoint</td>\n",
       "      <td>Great book!  Does not disappoint.  Wonderful c...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-11</td>\n",
       "      <td>RCU7OTNRDJBOS</td>\n",
       "      <td>Priscilla Seaton</td>\n",
       "      <td>Disturbing in its accurate reflection of human...</td>\n",
       "      <td>A very absorbing book. Not at all what I expec...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-10</td>\n",
       "      <td>R257OLQTPXYQ82</td>\n",
       "      <td>J</td>\n",
       "      <td>Superb</td>\n",
       "      <td>Lives intertwined, humor,sadness, superior sto...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-12-10</td>\n",
       "      <td>R1LNKO30KAXCUM</td>\n",
       "      <td>Roberta L. Sherrill</td>\n",
       "      <td>One Star</td>\n",
       "      <td>Disappointing..... finally quit reading it.  S...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5796</th>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>RT2TE0W92SL67</td>\n",
       "      <td>Tricia K.</td>\n",
       "      <td>Seriously?  $17 bucks for a computer file???  ...</td>\n",
       "      <td>Premise sounds dull as dirt.  For $17 for a co...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5797</th>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>R14ZGYPSP9H0Y7</td>\n",
       "      <td>Pretzel</td>\n",
       "      <td>A must read</td>\n",
       "      <td>The depth of character development and storyli...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5798</th>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>R1913ISIDAGQ1A</td>\n",
       "      <td>Prodigy</td>\n",
       "      <td>I love it</td>\n",
       "      <td>The book was great and I will love to re-read ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5799</th>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>R2JY771IW7RI3R</td>\n",
       "      <td>David Katz</td>\n",
       "      <td>Kendle price too expensive</td>\n",
       "      <td>I started to order the kindle edition and than...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5800</th>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>R22B7K1DUJR6ZN</td>\n",
       "      <td>M. A. Barnett</td>\n",
       "      <td>too expensive</td>\n",
       "      <td>I would love to buy this book but it is too ex...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5801 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date              id               author  \\\n",
       "0     2016-12-11  R3SH1N77GNTD9K                Stefi   \n",
       "1     2016-12-11   RVOEQK3JK4LY2      Amazon Customer   \n",
       "2     2016-12-11   RCU7OTNRDJBOS     Priscilla Seaton   \n",
       "3     2016-12-10  R257OLQTPXYQ82                    J   \n",
       "4     2016-12-10  R1LNKO30KAXCUM  Roberta L. Sherrill   \n",
       "...          ...             ...                  ...   \n",
       "5796  2012-09-27   RT2TE0W92SL67            Tricia K.   \n",
       "5797  2012-09-27  R14ZGYPSP9H0Y7              Pretzel   \n",
       "5798  2012-09-27  R1913ISIDAGQ1A              Prodigy   \n",
       "5799  2012-09-27  R2JY771IW7RI3R           David Katz   \n",
       "5800  2012-09-27  R22B7K1DUJR6ZN        M. A. Barnett   \n",
       "\n",
       "                                                  title  \\\n",
       "0                                            Great read   \n",
       "1                       Great book! Does not disappoint   \n",
       "2     Disturbing in its accurate reflection of human...   \n",
       "3                                                Superb   \n",
       "4                                              One Star   \n",
       "...                                                 ...   \n",
       "5796  Seriously?  $17 bucks for a computer file???  ...   \n",
       "5797                                        A must read   \n",
       "5798                                          I love it   \n",
       "5799                         Kendle price too expensive   \n",
       "5800                                      too expensive   \n",
       "\n",
       "                                                   body  star_rating  \n",
       "0     Very moving story. Great effortless writing wh...          5.0  \n",
       "1     Great book!  Does not disappoint.  Wonderful c...          5.0  \n",
       "2     A very absorbing book. Not at all what I expec...          4.0  \n",
       "3     Lives intertwined, humor,sadness, superior sto...          5.0  \n",
       "4     Disappointing..... finally quit reading it.  S...          1.0  \n",
       "...                                                 ...          ...  \n",
       "5796  Premise sounds dull as dirt.  For $17 for a co...          1.0  \n",
       "5797  The depth of character development and storyli...          5.0  \n",
       "5798  The book was great and I will love to re-read ...          5.0  \n",
       "5799  I started to order the kindle edition and than...          5.0  \n",
       "5800  I would love to buy this book but it is too ex...          1.0  \n",
       "\n",
       "[5801 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop(['date', 'id', 'author', 'title'],\n",
    "    axis = 1,\n",
    "    inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Very moving story. Great effortless writing wh...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great book!  Does not disappoint.  Wonderful c...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A very absorbing book. Not at all what I expec...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lives intertwined, humor,sadness, superior sto...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Disappointing..... finally quit reading it.  S...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5796</th>\n",
       "      <td>Premise sounds dull as dirt.  For $17 for a co...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5797</th>\n",
       "      <td>The depth of character development and storyli...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5798</th>\n",
       "      <td>The book was great and I will love to re-read ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5799</th>\n",
       "      <td>I started to order the kindle edition and than...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5800</th>\n",
       "      <td>I would love to buy this book but it is too ex...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5801 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body  star_rating\n",
       "0     Very moving story. Great effortless writing wh...          5.0\n",
       "1     Great book!  Does not disappoint.  Wonderful c...          5.0\n",
       "2     A very absorbing book. Not at all what I expec...          4.0\n",
       "3     Lives intertwined, humor,sadness, superior sto...          5.0\n",
       "4     Disappointing..... finally quit reading it.  S...          1.0\n",
       "...                                                 ...          ...\n",
       "5796  Premise sounds dull as dirt.  For $17 for a co...          1.0\n",
       "5797  The depth of character development and storyli...          5.0\n",
       "5798  The book was great and I will love to re-read ...          5.0\n",
       "5799  I started to order the kindle edition and than...          5.0\n",
       "5800  I would love to buy this book but it is too ex...          1.0\n",
       "\n",
       "[5801 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `NaN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1    2675\n",
      "-1    2156\n",
      " 0     967\n",
      "Name: polarity, dtype: int64\n",
      " 1    967\n",
      "-1    967\n",
      " 0    967\n",
      "Name: polarity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df.dropna(inplace = True)\n",
    "df['polarity'] = df.star_rating.apply(lambda rating: cmp(rating, 3))\n",
    "print df.polarity.value_counts()\n",
    "\n",
    "# positive = df[df.polarity == 1].sample(n = 967)\n",
    "# negative = df[df.polarity == -1].sample(n = 967)\n",
    "# neutral = df[df.polarity == 0]\n",
    "# df = positive.append(negative).append(neutral)\n",
    "ns = df.polarity.value_counts()\n",
    "\n",
    "for polarity in [-1, 0, 1]:\n",
    "    # how many to remove\n",
    "    n = ns[polarity] - ns.min()\n",
    "    # which ones to remove\n",
    "    index = df[df.polarity == polarity].sample(n, random_state = 0).index\n",
    "    # remove\n",
    "    df.drop(index, inplace = True)\n",
    "\n",
    "print df.polarity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive, neutral, and negatives reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature matrix and response vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f73d0e65295a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_c, test_c = cross_validation.train_test_split(X, c, stratify = c, train_size = .6, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### TF-IDF and `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformed feature matrix `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # TODO..."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:ga-course]",
   "language": "python",
   "name": "conda-env-ga-course-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
